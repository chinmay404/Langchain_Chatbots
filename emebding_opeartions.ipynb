{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import format_document\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "\n",
    "\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "key = os.getenv('GOOGLE_API_KEY')\n",
    "# llm = ChatGoogleGenerativeAI(\n",
    "#     model=\"gemini-1.5-pro\", temperature=0.1, api_key=key)\n",
    "llm = Ollama(model=\"qwen2:1.5b\")\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "persist_directory=\"./chroma_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"./doc.pdf\")\n",
    "data = loader.load_and_split()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=1)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "len(all_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(all_splits, gemini_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 1, 'source': './doc.pdf'}, page_content='A l g o r i t h m s A m a z o n  W e b  S e r v i c e s  \\x00 A W S \\x00 , C y b e r s e c u r i t y D j a n g o S e l e n i u m A I L L M s\\nR A G \\x00 R e t r i e v a l - A u g m e n t e d  G e n e r a t i o n ) L a n g C h a i n N g i n x R e s t  A P I D o c k e r\\nwww .enhancv .com\\ue06dPowered by•\\n•\\n•\\n•'),\n",
       " Document(metadata={'page': 1, 'source': './doc.pdf'}, page_content='Demonstrated strong problem-solving skills by addressing challenges during the development and testing phases.\\nCERTIFICATIONS\\nC y b e r s e c u r i t y  I n t e r n s h i p  \\x00  P a l o a l t o  \\x00 V i r t u a l )\\nP a l o a l t oA W S  A c a d e m y  G r a d u a t e  \\x00  A W S  A c a d e m y  C l o u d  \\nA r c h i t e c t i n g\\nA m a z o n  W e b  S e r v i c e s  \\x00 A W S \\x00'),\n",
       " Document(metadata={'page': 0, 'source': './doc.pdf'}, page_content=\"As an accomplished Computer Science\\xa0enthusiast,\\xa0and a passion for technology. With\\xa0a proven track record in developing web \\napplications, RAG Applications with AI, and a commitment to innovation, I'm excited to elevate my expertise through a Master's in \\nComputer Science. Having previously contributed to cutting-edge projects, I am eager to apply my skills and experience to drive\"),\n",
       " Document(metadata={'page': 0, 'source': './doc.pdf'}, page_content=\"meaningful advancements in the field.\\xa0My goal is\\xa0to excel in the technology industry and bring innovation to the forefront of \\ntomorrow's solutions.\\nEDUCATION\\nBachelor's degree in Computer Science\\nD .  Y .  P a t i l  C o l l e g e  o f  E n g i n e e r i n g  &  T e c h n o l o g y\\n01/2024 \\x00 Present\\xa0\\nHigher Secondary School in Science\\nN e w  M o d e l  J u n i o r  C o l l e g e\")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is The Document is About?\"\n",
    "matching_docs = db.similarity_search(query)\n",
    "matching_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=all_splits, embedding=gemini_embeddings, persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Chains in LangChain are a powerful tool that can be used for various purposes.\n",
    "Efficient Document Processing: Document Chains allow you to process and analyze large amounts of text data efficiently. They provide a structured approach to working with documents, enabling you to retrieve, filter, refine, and rank them based on specific criteria.\n",
    "\n",
    "Task Decomposition: Document Chains can help you break down complex tasks into smaller, more manageable subtasks. By using different types of Document Chains like Stuff, Refine, Map Reduce, or Map Re-rank, you can perform specific operations on the retrieved documents and obtain more accurate and relevant results.\n",
    "\n",
    "Improved Accuracy: Document Chains, especially Map Re-rank Chains, can help improve the accuracy of your responses. By running an initial prompt on each document and returning the highest-scoring response, you can prioritize the most reliable and accurate answers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff Chain\n",
    "One way to provide context to a language model is through the stuffing method.\n",
    "\n",
    "This involves putting all relevant data into the prompt for the LangChain’s StuffDocumentsChain to process.\n",
    "\n",
    "The advantage of this method is that it only requires one call to the LLM, and the model has access to all the information at once.\n",
    "\n",
    "However, one downside is that most LLMs can only handle a certain amount of context. For large or multiple documents, stuffing may result in a prompt that exceeds the context limit.\n",
    "\n",
    "Additionally, this method is only suitable for smaller amounts of data. When working with larger amounts, alternative approaches should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\",verbose=True)\n",
    "\n",
    "query = \"What type of document is this\"\n",
    "matching_docs = db.similarity_search(query)\n",
    "answer =  chain.run(input_documents=matching_docs, question=query)\n",
    "answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD History To CHAT BOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
